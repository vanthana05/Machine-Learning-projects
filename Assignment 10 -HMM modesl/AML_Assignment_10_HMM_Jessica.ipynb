{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Hidden Markov Models (HMMs)\n",
    "---\n",
    "\n",
    "_Author: Carleton Smith_\n",
    "\n",
    "<a id=\"guide\"></a>\n",
    "## Project Guide\n",
    "---\n",
    "- [Project Overview](#project-overview)    \n",
    "- [Part 1: Acquire, Explore, and Preprocess Data](#part1)\n",
    "- [Part 2: Components of a Hidden Markov Model](#part2)  \n",
    "- [Part 3: Estimating a Hidden Markov Model](#part3)\n",
    "\n",
    "\n",
    "<a id=\"project-overview\"></a>\n",
    "## Project Overview\n",
    "---\n",
    "#### EXPECTED TIME: 3 HRS  \n",
    "\n",
    "\n",
    "Some of the topics included in this assignment will include:\n",
    "\n",
    "-  Clustering\n",
    "-  Deciding the on the type of HMM problem\n",
    "-  Initializing and tuning HMM parameters\n",
    "\n",
    "\n",
    "**Motivation**: HMMs can be effective in solving problems in reinforcement learning and temporal pattern recognition.\n",
    "\n",
    "**Objectives**: By the end of this assignment, you will:\n",
    "- Understand the three problems HMMs can solve\n",
    "- Be able to learn a HMM parameters\n",
    "- Make predictions using a trained HMM\n",
    "\n",
    "**Problem**: Throughout this assignment, we will try to predict the weekly price of corn from a dataset taken from Kaggle.\n",
    "\n",
    "\n",
    "**Dataset**: [_Weekly Corn Prices_](https://www.kaggle.com/nickwong64/corn2015-2017) from the Kaggle, courtesy of Nick Wong.  \n",
    "\n",
    "Dataset description as provided on Kaggle:\n",
    "\n",
    "---\n",
    "_Content_    \n",
    "The file composed of simply 2 columns. The first column contain the date of the final day of each week, the other is corn close price. The timeframe goes from 2015-01-04 until 2017-10-01. The original data is downloaded from Quantopian corn futures price.\n",
    "\n",
    "_Inspiration_    \n",
    "William Gann: *Time is the most important factor in determining market movements and by studying past price records you will be able to prove to yourself history does repeat and by knowing the past you can tell the future. There is a definite relation between price and time.*\n",
    "\n",
    "Please see the [Data Folder](https://www.kaggle.com/nickwong64/corn2015-2017) to explore the dataset further.\n",
    "\n",
    "---\n",
    "\n",
    "## Note on this project\n",
    "\n",
    "The implementation of a HMM from scratch can involve complex code that you might not entirely understand. Becauae of this, this implementation is not intended to be the most robust and efficient. The assignment prioritizes the demonstation of the algorithm's steps while maintaining reproducibility. As such, certain tasks and non-essential features to the algorithm itself (ex: `Signature` and `Parameter` classes) are defined and implemented without explanation. Students are not expected to understand the entirety of the code base. Rather, students will be tested on their high level understanding of HMM and some critical functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<a id=\"questions\"></a>\n",
    "## Questions\n",
    "\n",
    "+ [Question 01](#q01)\n",
    "+ [Question 02](#q02)\n",
    "+ [Question 03](#q03)\n",
    "+ [Question 04](#q04)\n",
    "+ [Question 05](#q05)\n",
    "+ [Question 06](#q06)\n",
    "+ [Question 07](#q07)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "from itertools import permutations, chain, product\n",
    "from sklearn.cluster import KMeans\n",
    "from inspect import Signature, Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Define path constants\n",
    "ROOT_DIR = '../resource/asnlib/publicdata/'\n",
    "CORN_2013_2017 = 'corn2013-2017.txt'\n",
    "CORN_2015_2017 = 'corn2015-2017.txt'\n",
    "OHL = 'corn_OHLC2013-2017.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<a id=\"part1\"></a>\n",
    "## Part 1: Acquire, Explore, and Preprocess Data\n",
    "\n",
    "### Acquire and Explore\n",
    "\n",
    "Below we read the data we are interested in using `Pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "corn13_17 = pd.read_csv(ROOT_DIR+CORN_2013_2017, names = (\"week\",\"price\") )\n",
    "corn15_17 = pd.read_csv(ROOT_DIR+CORN_2015_2017, names = (\"week\",\"price\"))\n",
    "OHL_df = pd.read_csv(ROOT_DIR+OHL, names = (\"week\",\"open\",\"high\",\"low\",\"close\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Throughout this assignment, we will be using just the  `corn13_17` dataset. However, feel free to experiment using \n",
    "other datasets provided.\n",
    "\n",
    "Below, we display the first 5 columns of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-06</td>\n",
       "      <td>7.794975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>7.863400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-20</td>\n",
       "      <td>8.234920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>8.186260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-02-03</td>\n",
       "      <td>8.317480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         week     price\n",
       "0  2013-01-06  7.794975\n",
       "1  2013-01-13  7.863400\n",
       "2  2013-01-20  8.234920\n",
       "3  2013-01-27  8.186260\n",
       "4  2013-02-03  8.317480"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corn13_17.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Next, we inspect the data for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 248 entries, 0 to 247\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   week    248 non-null    object \n",
      " 1   price   248 non-null    float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 4.0+ KB\n"
     ]
    }
   ],
   "source": [
    "corn13_17.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "From the output above, the data appear to be complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Preprocess: Discretization\n",
    "\n",
    "As mentioned in Lecture 11-1, there are two types of HMM:\n",
    "\n",
    "- 1. Discrete HMM\n",
    "- 2. Continuous HMM\n",
    "\n",
    "The typical structure of a HMM involves a discrete number of latent (\"hidden\") states that are unobserved. The observations, which in our case are corn prices, are generated from a state dependent \"emissions\" (or \"observations\") distribution. \n",
    "\n",
    "In discrete HMM, the emissions are discrete values. Conversely, in continuous HMM, the emissions are continuous. In the latter, the distribution that generates the emissions is usually assumed to be Gaussian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<a id=\"q01\"></a>\n",
    "[Return to top](#questions)\n",
    "\n",
    "### Question 01\n",
    "\n",
    "Decide wheter the following statement is true or false.\n",
    "\n",
    "*The number of discrete states is a hyperparameter of a HMM.*\n",
    "\n",
    "Assign a boolean value to the variable ans1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "ans1 = True\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q-01",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "In order to simplify the problem, in come cases, it is advisable to use clustering in order to discretize continuous HMM emissions.\n",
    "\n",
    "We will see how to do this in the next section.\n",
    "\n",
    "### Generate Clusters\n",
    "\n",
    "As noted in Lecture 11-4, clustering a sequence of continuous observations is a form of data quantization. This can simplify the learning of an HMM.\n",
    "\n",
    "Instead of calculating probabilities a posteriori from a continuous emissions sequence, we can use the respective observation cluster label as the observation. This way, the emission probability matrix can be encoded as a discrete vector of probabilities.\n",
    "\n",
    "<a id=\"q02\"></a>\n",
    "[Return to top](#questions)\n",
    "\n",
    "### Question 02\n",
    "\n",
    "Define a  function called `generate_cluster_assignments` that accepts the following arguments\n",
    "\n",
    "- A `Pandas` series.\n",
    "- The desired number of cluster.\n",
    "\n",
    "Your function should instantiate an `sklearn` KMeans class using the specified number of clusters and random_state=24. Your function should return a `Pandas` series of cluster labels for each observation in the sequence. \n",
    "\n",
    "For example, if we set \n",
    "\n",
    "`data_series = pd.Series([1,2,3,2,1,2,3,2,1,2,3,2,1,2,3,2,1,6,7,8,7,6,7,8,6,7,6,7,8,7,7,8,56,57,58,59,57,58,6,7,8,1,2])`\n",
    "\n",
    "Then calling the function by using\n",
    "\n",
    "`labels = generate_cluster_assignments(data_series, clusters = 3)`\n",
    "\n",
    "Should return\n",
    "\n",
    "`labels = array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2,2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1])`\n",
    "\n",
    "Note that KMeans object can be instantiated via the following command:\n",
    "\n",
    "`clusterer = KMeans(args)`\n",
    "\n",
    "Moreover, your particular labels might not match exactly, but the **clusters** should be the same.\n",
    "\n",
    "*Hint*: That KMeans object has `.fit()` and `.predict()` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "def generate_cluster_assignments(ser, clusters):\n",
    "    cluster = KMeans(n_clusters=clusters,random_state=24)\n",
    "    df=pd.DataFrame(ser)\n",
    "    cluster.fit(df)\n",
    "    return cluster.predict(df)\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q-02",
     "locked": true,
     "points": "25",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Cluster 2013-2017\n",
    "corn13_17_seq = generate_cluster_assignments(corn13_17[['price']], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3,\n",
       "       3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 3, 3, 3, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corn13_17_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<a id=\"part2\"></a>\n",
    "## Part 2: Components of a Hidden Markov Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### HMM Parameters\n",
    "\n",
    "A HMM consists of 5 components:\n",
    "\n",
    "- N -- The number of hidden states : this is a discrete integer that the practitioner provides. It is the number of assumed hidden states.\n",
    "\n",
    "- A -- State transition matrix: With N=2, the transition matrix may look like the following\n",
    "\n",
    "\n",
    "$$ A = \\begin{bmatrix}\n",
    "   . & S1 & S2 \\\\\\\n",
    "   S1 & .7 & .3 \\\\\\\n",
    "   S2 & .6 & .4\n",
    "  \\end{bmatrix}$$\n",
    "\n",
    "The first row of A shows the probability of transitioning from state 1 --> (state 1=0.7, state 2=0.3).\n",
    "The second row of A shows the probability of transitioning from state 2 --> (state 1=0.6, state 2=0.4).\n",
    "  \n",
    "- B -- Emission probability matrix: Setting the number of unique observation M==4, B may look like\n",
    "\n",
    " $$ B = \\begin{bmatrix}\n",
    "     . &a & b  &  c &  d \\\\\\ \n",
    "    S1 & .4 & .3 & .1 & .2 \\\\\\\n",
    "    S2 & .1 & .4 & .1 & .4\n",
    "  \\end{bmatrix}$$\n",
    "  \n",
    "The rows correspond to state 1 and state 2, respectively. The columns in B correspond to the probability of that observation, given the respective state.\n",
    "For example, the probability of observing $d$ in $S1$ = $0.2$.\n",
    "\n",
    "- $\\pi$ -- Starting likelihood (initial state probabilities). $\\pi$ may take the following form\n",
    "\n",
    "$$\\pi =  \\begin{bmatrix}\n",
    "                       .5 \\\\\n",
    "                       .5\n",
    "                        \\end{bmatrix}$$\n",
    "\n",
    "In this case,it means that the sequence of states is equally likely to start in $S1$ or $S2$\n",
    "\n",
    "\n",
    "- $(x_{i}, ..., x_{T})$ -- Sequence of emissions, or observations\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "The only component of an HMM that will always be know is the sequence of observations, $(x_{i}, ..., x_{T})$. The type of HMM problem is determined by which of these components are known and the motivation of the problem. We will discuss the types of HMM problems next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<a id=\"q03\"></a>\n",
    "[Return to top](#questions)\n",
    "\n",
    "### Question 03\n",
    "\n",
    "If \"N\" is the number of states, then the shape of \"A\" (the transition matrix) will always be: \n",
    "\n",
    "- a) 2 x 2\n",
    "- b) N x N\n",
    "- c) N x number of unique observations\n",
    "- d) None of the above\n",
    "\n",
    "Assign the character associated with your choice as a string to the variable `ans3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "ans3 = 'b'\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q-03",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<a id=\"q04\"></a>\n",
    "[Return to top](#questions)\n",
    "\n",
    "\n",
    "\n",
    "### Question 4\n",
    "\n",
    "If \"N\" is the number of states, then the shape of \"B\" (the emission matrix) will always be:\n",
    "\n",
    "- a) 2 x 4\n",
    "- b) N x N\n",
    "- c) N x number of unique observations\n",
    "- d) None of the above\n",
    "\n",
    "Assign the character associated with your choice as a string to the variable ans4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "ans4 = 'c'\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q-04",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Types of Problems using HMM\n",
    "\n",
    "In Lecture 11-2, we described three HMM estimation problems:\n",
    "\n",
    "1. State Estimation\n",
    "2. State Sequence\n",
    "3. Learn an HMM\n",
    "\n",
    "Below, we will briefly cover the motivation of each estimation problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**1. State Estimation**: \n",
    "\n",
    "- Given an HMM ($\\pi$, _A_, *B*), and an observation sequence $(x_{i}, ..., x_{T})$, estimate the state probability for $x_{i}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**2. State Sequence**: \n",
    "\n",
    "- Given an HMM ($\\pi$, _A_, *B*), and an observation sequence $(x_{i}, ..., x_{T})$, estimate the most probable state sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**3. Learn an HMM**: \n",
    "\n",
    "- Given an observation sequence $(x_{i}, ..., x_{T})$, estimate the HMM parameters ($\\pi$, _A_, *B*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<a id=\"q05\"></a>\n",
    "[Return to top](#questions)\n",
    "\n",
    "### Question 5\n",
    "\n",
    "\n",
    "Which of the following HMM problems uses the Forward-Backward Algorithm to estimate the solution?\n",
    "\n",
    "- a) State Estimation\n",
    "- b) State Sequence\n",
    "- c) Learn an HMM\n",
    "- d) None of the above\n",
    "- e) All of the above\n",
    "\n",
    "\n",
    "List all the answers that apply as 'a', 'b', 'c', 'd', and/or 'e' in the list assigned to the variable `ans5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "ans5 = ['a','c']\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q-05",
     "locked": true,
     "points": "12",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<a id=\"q06\"></a>\n",
    "[Return to top](#questions)\n",
    "\n",
    "### Question 06\n",
    "\n",
    "Which of the following HMM problems uses the Viterbi Algorithm to estimate the solution?\n",
    "\n",
    "\n",
    "- a) State Estimation\n",
    "- b) State Sequence\n",
    "- c) Learn an HMM\n",
    "- d) None of the above\n",
    "- e) All of the above\n",
    "\n",
    "\n",
    "List all the answers that apply as 'a', 'b', 'c', 'd', and/or 'e' in the list assigned to the variable `ans6`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "ans6 = ['b']\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q-06",
     "locked": true,
     "points": "12",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<a id=\"part3\"></a>\n",
    "## Part 3: Estimating a Hidden Markov Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "In this section, you will be guided through an exercise using the third HMM estimation problem: **Learn an HMM**\n",
    "\n",
    "We will use the the Corn Prices 2013-2017 dataset from Kaggle as our sequence of observations.\n",
    "\n",
    "In Question 02 we asked you to make a function to discretize a Pandas Series into a specified number of clusters. We will use this function now to discretize our price data into 5 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3,\n",
       "       3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 3, 3, 3, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4], dtype=int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cluster 2013-2017\n",
    "corn13_17_seq = generate_cluster_assignments(corn13_17[['price']], 5)\n",
    "corn13_17_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**NOTE:** Quite a few functions are provided in the following cells. It is not imperative that you completely understand how each of them work. Many of them are helper functions that perform a specific task within another function. What is important is that you understand the procedure that is occuring to estimate the HMM parameters. Those steps are laid out in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Steps for Learning a HMM\n",
    "\n",
    "The Expectation Maximization (EM) algorithm is used to estimate the parameters of a HMM given a sequence of observations (or emissions). Here are the general steps for this procedure:\n",
    "\n",
    "\n",
    "1. Initialize a set of parameters for the HMM ($\\pi$, _A_, *B*)\n",
    "2. Conduct the EM algorithm:\n",
    "    - The E Step: Use forward-backward algorithm to calculate the probability of observing the emissions with the given HMM parameters ($\\pi$, _A_, *B*)\n",
    "    - The M Step: Update the HMM parameters so that the sequence of observations are more likely to have come from this particular HMM\n",
    "3. Repeat steps 1 and 2 until the HMM parameters have converged.\n",
    "<br>\n",
    "\n",
    "\n",
    "The remaining parts of this assignment will perform this procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Important Constant: Number of Unique States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Almost all functions require this constant as an argument\n",
    "STATE_LIST = ['S1', 'S2']\n",
    "\n",
    "# Initialze state transition probabilities (2 states)\n",
    "STATE_TRANS_PROBS = [0.4, 0.6, 0.35, 0.55]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Helper Functions\n",
    "\n",
    "These functions are used to perform common tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# given a list with unique items, this function will return a new list with all permutations\n",
    "def make_state_permutations(list_of_unique_states):\n",
    "    l1 = [''.join(tup) for tup in permutations(list_of_unique_states, 2)]\n",
    "    l2 = [state+state for state in list_of_unique_states]\n",
    "    return sorted(l1 + l2)\n",
    "\n",
    "# helper function in EM function\n",
    "def _grab_highest_prob_and_state(state_permutations_lst, prob_arr):\n",
    "    return (prob_arr[np.argmax(prob_arr)], state_permutations_lst[np.argmax(prob_arr)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**The following two functions transform a dictionary to a different format.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def dict_to_tuples(list_of_unique_states, d):\n",
    "    \"\"\"\n",
    "    list_of_unique_states: List of unique state names, as strings\n",
    "    d: Dictionary of state transition probabilities\n",
    "    \n",
    "    \n",
    "    EXAMPLE:\n",
    "    s_perms = ['S1S1', 'S1S2', 'S2S1', 'S2S2']\n",
    "    p_list = [0.1, 0.9, 0.4, 0.6]\n",
    "    d = {'S1S1': 0.1, 'S1S2': 0.9, 'S2S1': 0.4, 'S2S2': 0.6}\n",
    "    \n",
    "    print(dict_to_tuples(d))\n",
    "    \n",
    "    OUTPUT:\n",
    "    {S1: (0.1, 0.9), S2: (0.4, 0.6)}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Defensive programming to ensure output will be correct\n",
    "    list_of_unique_states = sorted(list_of_unique_states)\n",
    "    assert make_state_permutations(list_of_unique_states) == list(d.keys()), \\\n",
    "            \"Keys of dictionary must match output of `make_state_permutations(list_of_unique_states)`\"\n",
    "    \n",
    "    lengths = [len(st) for st in list_of_unique_states]\n",
    "    final_dict = {}\n",
    "    for idx, st in enumerate(list_of_unique_states):\n",
    "        tup = []\n",
    "        for trans_p in d.keys():\n",
    "            if trans_p[:lengths[idx]] == st:\n",
    "                tup.append(d[trans_p])\n",
    "            else:\n",
    "                continue\n",
    "        final_dict[st] = tuple(tup)\n",
    "        \n",
    "    return final_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def obs_to_tuples(list_of_unique_states, d, sequence):\n",
    "    \"\"\"\n",
    "    list_of_unique_states: List of unique state names, as strings\n",
    "    d: Dictionary of obs transition probabilities\n",
    "    sequence: the observation sequence\n",
    "    \n",
    "    \n",
    "    EXAMPLE:\n",
    "    STATE_LIST = ['S1', 'S2']\n",
    "    d = {'S1_0': 0.1,\n",
    "         'S1_1': 0.3,\n",
    "         'S1_2': 0.4,\n",
    "         'S1_3': 0.15,\n",
    "         'S1_4': 0.05,\n",
    "         'S2_0': 0.15,\n",
    "         'S2_1': 0.2,\n",
    "         'S2_2': 0.3,\n",
    "         'S2_3': 0.05,\n",
    "         'S2_4': 0.3}\n",
    "    corn15_17_seq = generate_cluster_assignments(corn15_17[['price']], 5)\n",
    "    \n",
    "    print(obs_to_tuples(STATE_LIST, d))\n",
    "    \n",
    "    OUTPUT:\n",
    "    {'S1': (0.1, 0.3, 0.4, 0.15, 0.05), 'S2': (0.15, 0.2, 0.3, 0.05, 0.3)}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Defensive programming to ensure output will be correct\n",
    "    list_of_unique_states = sorted(list_of_unique_states)\n",
    "    num_unique_obs = len(np.unique(sequence))\n",
    "    \n",
    "    lengths = [len(st) for st in list_of_unique_states]\n",
    "    final_dict = {}\n",
    "    for idx, st in enumerate(list_of_unique_states):\n",
    "        tup = []\n",
    "        for e_trans in d.keys():\n",
    "            if e_trans[:lengths[idx]] == st:\n",
    "                tup.append(d[e_trans])\n",
    "            else:\n",
    "                continue\n",
    "        final_dict[st] = tuple(tup)\n",
    "        \n",
    "    return final_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Define Transition Functions\n",
    "\n",
    "The following three function definitions (all starting with `generate`) will be used to create our initial HMM parameters ($\\pi$, $A$, $B$) in the form of a dictionary.\n",
    "\n",
    "\n",
    "The functions are flexible enough to create ($\\pi$, $A$, $B$) from user specified values, or provide default uniform probability vectors if no values are explicitly given in the `**kwargs` argument.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### An Aside: Why dictionaries and not arrays?\n",
    "For this exercise, as data structure, we use dictonaries instead of arrays to improve efficiency and accuracy. The functions defined for this procedure involve retrieving values from data structures frequently and altering existing values. This is best done in a dictionary rather than in an array because dictionaries utilize hashing functions to look up data instead of indexed positions.\n",
    "\n",
    "To demonstate the speed benefits of using dictionaries to retrieve values, consider the time needed to retrieve a piece of data from both an array and a dictionary in the following exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seconds to index an array 10000000 times: 1.2123784039977181\n",
      "\n",
      " ############################################################ \n",
      "\n",
      "Seconds to retrieve value 10000000 times: 0.26255111299906275\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "all_setup = \"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# These hold the same information\n",
    "arr = np.array([[0.4, 0.6], [0.35, 0.55]])\n",
    "d = {'S1S1': 0.4, 'S1S2': 0.6, 'S2S1': 0.35, 'S2S2': 0.55}\n",
    "\n",
    "\"\"\"\n",
    "i = 10_000_000\n",
    "index_an_array = 'arr[0,0]'\n",
    "retrieve_value = \"d['S1S1']\"\n",
    "\n",
    "print('Seconds to index an array {} times: {}'.format(\n",
    "    i, timeit.timeit(setup=all_setup, stmt=index_an_array, number=i)))\n",
    "\n",
    "print('\\n','#' * 60, '\\n')\n",
    "print('Seconds to retrieve value {} times: {}'.format(i, timeit.timeit(setup=all_setup, stmt=retrieve_value, number=i)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**The following functions generate initial probabilities for ($\\pi$, $A$, $B$)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def generate_state_trans_dict(list_of_unique_states, **kwargs):\n",
    "    '''\n",
    "    \n",
    "    'list_of_unique_states': list of states as strings\n",
    "    ''**kwargs': keyword being the state and value is tuple of state transitions.\n",
    "    <Must be listed in same order as listed in 'list_of_unique_states'>\n",
    "    \n",
    "    If **kwargs omitted, transitions are given uniform distribution based on\n",
    "    number of states.\n",
    "    \n",
    "    EXAMPLE1:\n",
    "    state_params = generate_state_trans_dict(['S1', 'S2', 'S3'])\n",
    "    \n",
    "    OUTPUT1:\n",
    "    {'S1S1': 0.5, 'S2S2': 0.5, 'S1S2': 0.5, 'S2S1': 0.5}\n",
    "     \n",
    "    EXAMPLE2:\n",
    "    state_params = generate_state_trans_dict(['S1', 'S2'], S1=(0.1, 0.9), S2=(0.4, 0.6))\n",
    "    \n",
    "    OUTPUT2:\n",
    "    {'S1S1': 0.1, 'S1S2': 0.9, 'S2S1': 0.4, 'S2S2': 0.6}\n",
    "    \n",
    "    '''\n",
    "    # number of states\n",
    "    N = len(list_of_unique_states)\n",
    "    \n",
    "    # this runs if specific transitions are provided\n",
    "    if kwargs:\n",
    "        state_perms = [''.join(tup) for tup in permutations(list(kwargs.keys()), 2)]\n",
    "        all_permutations = [state+state for state in list_of_unique_states] + state_perms\n",
    "        pbs = chain.from_iterable(kwargs.values())\n",
    "        state_trans_dict = {perm:p for perm, p in zip(sorted(all_permutations), pbs)}\n",
    "        return state_trans_dict\n",
    "    \n",
    "    state_perms = [''.join(tup) for tup in permutations(list_of_unique_states, 2)]\n",
    "    all_permutations = [state+state for state in list_of_unique_states] + state_perms\n",
    "    state_trans_dict = {perm: (1/N) for perm in all_permutations}\n",
    "    return state_trans_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def generate_emission_prob_dist(list_of_unique_states, sequence, **kwargs):\n",
    "    '''\n",
    "    list_of_unique_states: list of states as strings\n",
    "    sequence: array of observations\n",
    "    \n",
    "    EXAMPLE1:\n",
    "    corn15_17_seq = generate_cluster_assignments(corn15_17[['price']])\n",
    "    STATE_LIST = ['S1', 'S2']\n",
    "    \n",
    "    generate_emission_prob_dist(STATE_LIST, corn15_17_seq, S1=(0.1, 0.3, 0.4, 0.15, 0.05))\n",
    "    \n",
    "    OUTPUT1:\n",
    "    {'S1_0': 0.1,\n",
    "     'S1_1': 0.3,\n",
    "     'S1_2': 0.4,\n",
    "     'S1_3': 0.05,\n",
    "     'S1_4': 0.05,\n",
    "     'S2_0': 0.2,\n",
    "     'S2_1': 0.2,\n",
    "     'S2_2': 0.2,\n",
    "     'S2_3': 0.2,\n",
    "     'S2_4': 0.2}\n",
    "    '''\n",
    "    # number of unique obs\n",
    "    B = list(np.unique(sequence).astype(str))\n",
    "    \n",
    "    # this runs if specific transitions are provided\n",
    "    if kwargs:\n",
    "        for t in kwargs.values():\n",
    "            assert len(t) == len(B), \"Must provide all probabilities for unique emissions in given state.\"\n",
    "            assert round(np.sum(t)) == 1.0, \"Given emission probabilities for a state must add up to 1.0\"\n",
    "        for k in kwargs.keys():\n",
    "            assert k in list_of_unique_states, \"Keyword arguments must match a value included in `list_of_unique_states`\"\n",
    "        diff = list(set(list_of_unique_states).difference(kwargs.keys()))\n",
    "        \n",
    "        pbs = chain.from_iterable(kwargs.values())\n",
    "        obs_perms = [state + '_' + str(obs) for state in kwargs.keys() for obs in B]\n",
    "        \n",
    "        obs_trans_dict = {perm:p for perm, p in zip(sorted(obs_perms), pbs)}\n",
    "        \n",
    "        if diff:\n",
    "            obs_perms_diff = [state + '_' + obs for state in diff for obs in B]\n",
    "            obs_trans_dict.update({perm: (1/len(B)) for perm in obs_perms_diff})\n",
    "            \n",
    "        return obs_trans_dict\n",
    "    \n",
    "    obs_perms = [state + '_' + obs for state in list_of_unique_states for obs in B]\n",
    "    obs_trans_dict = {perm: (1/len(B)) for perm in obs_perms}\n",
    "    return obs_trans_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_init_prob_dist(list_of_unique_states, **kwargs):\n",
    "    \"\"\"\n",
    "    Examples:\n",
    "    STATE_LIST = ['S0','S1','S2','S3','S4']\n",
    "    initial_states = {'S1':.2, 'S2':.3, 'S3':.05, 'S4':.25, 'S0':.2}\n",
    "    \n",
    "    print(generate_init_prob_dist(STATE_LIST))\n",
    "    # --> {'S0': 0.2, 'S1': 0.2, 'S2': 0.2, 'S3': 0.2, 'S4': 0.2}\n",
    "    \n",
    "    print(generate_init_prob_dist(STATE_LIST, **initial_states))  ### NOTE: must unpack dictionary with **\n",
    "    # --> {'S1': 0.2, 'S2': 0.3, 'S3': 0.05, 'S4': 0.25, 'S0': 0.2}\n",
    "    \"\"\"\n",
    "    \n",
    "    # number of states\n",
    "    N = len(list_of_unique_states)\n",
    "    \n",
    "    # this runs if specific transitions are provided\n",
    "    if kwargs:\n",
    "        for t in kwargs.values():\n",
    "            assert isinstance(t, float), \"Must provide probabilities as floats.\"\n",
    "            assert t > 0, \"Probabilities must be greater than 0.\"\n",
    "        assert np.sum(list(kwargs.values())) == 1.0, \"Given probabilities must add up to 1.0\"\n",
    "        assert len(kwargs) == len(list_of_unique_states), \"Please provide initial probabilities for all states, or leave blank\"\n",
    "        \n",
    "        # build the prob dictionary\n",
    "        init_prob_dict = {item[0]: item[1] for item in kwargs.items()}\n",
    "        return init_prob_dict\n",
    "    \n",
    "    init_prob_dist = {state: (1/N) for state in list_of_unique_states}\n",
    "    return init_prob_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Create a Priori State Transition \n",
    "\n",
    "We will use the functions defined above to permutate  state transistions and to create  a matrix with such entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S1S1': 0.4, 'S1S2': 0.6, 'S2S1': 0.35, 'S2S2': 0.55}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make permutations of state transition (this len should match len(STATE_TRANS_PROBS))\n",
    "state_transitions_list = make_state_permutations(STATE_LIST)\n",
    "\n",
    "# Create transition matrix in form of dictionary\n",
    "state_transition_probs = {\n",
    "    trans: prob for trans, prob in zip(state_transitions_list, STATE_TRANS_PROBS)\n",
    "}\n",
    "\n",
    "state_transition_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Above the state transition matrix is formatted as a dictionary. \n",
    "\n",
    "This dictonary can also be represented in another format. This second format will be more convenient we provided  `**kwargs` argument. This transformation can be done with the function `dict_to_tuples` as displayed in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S1': (0.4, 0.6), 'S2': (0.35, 0.55)}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform dictionary to be in tuple format\n",
    "#### - this format is required in the `generate_*` functions used later\n",
    "A_prior = dict_to_tuples(STATE_LIST, state_transition_probs)\n",
    "A_prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### NOTE ON FORMATTING\n",
    "\n",
    "Some functions in this assignment require the transition probabilities be in a specific format. We will switch between two formats that hold the same information:\n",
    "<br>\n",
    "\n",
    "\n",
    "**Format 1**: `{'S1S1': 0.4, 'S1S2': 0.6, 'S2S1': 0.35, 'S2S2': 0.55}`\n",
    "\n",
    "The above dictionary contains the state transition matrix. Every key  defines the likelhood of transitioning from one state to another. For example, the key-value pair, `'S1S2': 0.6`, says the probability of the state moving from `S1` to `S2`, from observation `i` to observation `j, is `0.6`.\n",
    "\n",
    "\n",
    "**Format 2**: `{'S1': (0.4, 0.6), 'S2': (0.35, 0.55)}`    \n",
    "\n",
    "The second format contains the same information as the first, but encodes the probabilities in tuples. With only two states and assuming `S1` is the first state, `'S1': (0.4, 0.6)` is interpreted as the probability of staying in `S1` is 0.4 and the probability of moving from `S1` to `S2` is 0.6. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Create Emission Probability  Priors\n",
    "\n",
    "We initiaize some emission probabilities manually in same formato at **Format 1** above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Manually initialize emission probabilities - in format 1\n",
    "B_format1 = {\n",
    "    'S1_0': 0.1,\n",
    "    'S1_1': 0.3,\n",
    "    'S1_2': 0.4,\n",
    "    'S1_3': 0.15,\n",
    "    'S1_4': 0.05,\n",
    "    'S2_0': 0.15,\n",
    "    'S2_1': 0.2,\n",
    "    'S2_2': 0.3,\n",
    "    'S2_3': 0.05,\n",
    "    'S2_4': 0.3\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The emission probabilities can be stored in dictionary format as well. Using the function `obs_to_tuples()` function in the cell below, we convert the emission probabilities to a dictionary format that is well suited to be provided as an argument in `**kwargs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S1': (0.1, 0.3, 0.4, 0.15, 0.05), 'S2': (0.15, 0.2, 0.3, 0.05, 0.3)}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert emission matrix to format 2\n",
    "B_format2 = obs_to_tuples(STATE_LIST, B_format1, corn13_17_seq)\n",
    "B_format2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The emission probabilities can be converted back to the original format by using the previously defined `generate_emission_prob_dist` function. This is demonstrated in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S1_0': 0.1,\n",
       " 'S1_1': 0.3,\n",
       " 'S1_2': 0.4,\n",
       " 'S1_3': 0.15,\n",
       " 'S1_4': 0.05,\n",
       " 'S2_0': 0.15,\n",
       " 'S2_1': 0.2,\n",
       " 'S2_2': 0.3,\n",
       " 'S2_3': 0.05,\n",
       " 'S2_4': 0.3}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use `generate_emission_prob_dist` to convert B back to format 1\n",
    "generate_emission_prob_dist(STATE_LIST, corn13_17_seq, **B_format2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "We will keep the emission probabilities in the `\"key\": tuple` format so that it can be used easily as a `**kwargs` argument later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "B_prior = obs_to_tuples(STATE_LIST, B_format1, corn13_17_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Let's recap.\n",
    "\n",
    "A fair amount of setup has already occurred and we have not yet started the HMM Learning procedure. Let's take a moment to recap the important elements we have established so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**We have a state transition matrix, $A$ (prior for $A$)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S1': (0.4, 0.6), 'S2': (0.35, 0.55)}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**We have an emissions probability matrix, $B$ (prior for $B$)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S1': (0.1, 0.3, 0.4, 0.15, 0.05), 'S2': (0.15, 0.2, 0.3, 0.05, 0.3)}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**We need an initial state probability matrix, $\\pi$. We will use `generate_init_prob_dist` to do this.**\n",
    "\n",
    "We can also use the `generate_init_prob_dist` function without specified parameters to make uniform initial state probabilities.\n",
    "\n",
    "_Note: If `pi__init` is not provided, a uniform distribution is produced based on number of states._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S1': 0.4, 'S2': 0.6}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# User specified initial probabilities\n",
    "pi__init = {'S1': 0.4 , 'S2': 0.6}\n",
    "\n",
    "# generate the dictionary holding initial state probabilities\n",
    "pi = generate_init_prob_dist(STATE_LIST, **pi__init)\n",
    "pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S1': 0.5, 'S2': 0.5}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using default initial parameters - demonstration only, we won't save this dictionary\n",
    "generate_init_prob_dist(STATE_LIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**And we have defined a number of functions that will be involved in the EM algorithm in some way**\n",
    "\n",
    "A summary of the constants and functions defined above is given below:\n",
    "\n",
    "_Constants_:    \n",
    "STATE_LIST    \n",
    "STATE_TRANS_PROBS     \n",
    "\n",
    "_Functions_:    \n",
    "`generate_cluster_assignments`    \n",
    "`make_state_permutations`    \n",
    "`_grab_highest_prob_and_state`    \n",
    "`dict_to_tuples`    \n",
    "`obs_to_tuples`    \n",
    "`generate_state_trans_dict`    \n",
    "`generate_emission_prob_dist`    \n",
    "`generate_init_prob_dist`    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Finally, we need to create a data structure that will hold all of our probability calculations until we are finished computing the E Step of the EM algorithm**\n",
    "\n",
    "For this task, we will take advantage of a powerful data structure from the `collections` module: `namedtuple`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### NAMED TUPLES\n",
    "\n",
    "Take a few minutes to review the [documentation](https://docs.python.org/3.6/library/collections.html#collections.namedtuple) on `namedtuples`. Then answer the following question.\n",
    "\n",
    "Alternatively, for a short and helpful introduction, review [this tutorial](https://dbader.org/blog/writing-clean-python-with-namedtuples).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<a id=\"q07\"></a>\n",
    "[Return to top](#questions)\n",
    "\n",
    "### Question 07\n",
    "\n",
    "Consider the following array of probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "probs = np.array([0.3, 0.7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Create a *namedtuple* factory called 'state' that has two field names: `prob1` and `prob2`. After defining the factory, instantiate an instance of the 'state' factory called `my_state` and store the two probabilities contained in the array `probs` defined above in the `prob1` and `prob2` field names, respectively. Assign the value of the `prob1` field name to `ans7` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "state = namedtuple('state','prob1 prob2')\n",
    "my_state = state(probs[0],probs[1])\n",
    "ans7 = my_state.prob1\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q-07",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "We now have all the pieces to use the EM algorithm. To do this requires the calculation of forward backward algorithm. We will use what we recently learned about `namedtuple` from the `collections` module to do this.\n",
    "\n",
    "The function below will generate this data structure for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def generate_obs_data_structure(sequence):\n",
    "    #  sequence: 1D numpy array of observations\n",
    "    ObservationData = namedtuple(\n",
    "        'ObservationData',\n",
    "        ['prob_lst', 'highest_prob', 'highest_state']\n",
    "    )\n",
    "    return {index+1: ObservationData for index in np.arange(len(sequence)-1)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### STEP 1: ESTIMATE PROBABILITIES:\n",
    "\n",
    "This step involves using the Forward-Backward algorithm to calculate the probability of observing a sequence, given a set of HMM parameters. We have all the tools to do this now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Enforce an Argument Signature on following function to prevent errors with **kwargs\n",
    "params = [Parameter('list_of_unique_states', Parameter.POSITIONAL_OR_KEYWORD),\n",
    "         Parameter('sequence', Parameter.POSITIONAL_OR_KEYWORD),\n",
    "         Parameter('A', Parameter.KEYWORD_ONLY, default=generate_state_trans_dict),\n",
    "         Parameter('B', Parameter.KEYWORD_ONLY, default=generate_emission_prob_dist),\n",
    "         Parameter('pi', Parameter.KEYWORD_ONLY, default=generate_init_prob_dist)]\n",
    "\n",
    "sig = Signature(params)\n",
    "\n",
    "def calculate_probabilities(list_of_unique_states, sequence, **kwargs):\n",
    "    \n",
    "    # enforce signature to ensure variable names\n",
    "    bound_values = sig.bind(list_of_unique_states, sequence, **kwargs)\n",
    "    bound_values.apply_defaults()\n",
    "\n",
    "    \n",
    "    # grab params that are left to default values\n",
    "    param_defaults = [(name, val) for name, val in bound_values.arguments.items() if callable(val)]\n",
    "    \n",
    "    # grab non-default params\n",
    "    set_params = [(name, val) for name, val in bound_values.arguments.items() if isinstance(val, dict)]\n",
    "    \n",
    "    # this will run if any default hmm parameters are used\n",
    "    if param_defaults:\n",
    "        for name, val in param_defaults:\n",
    "            if name == 'B':\n",
    "                B = val(list_of_unique_states, sequence)\n",
    "            elif name == 'A':\n",
    "                A = val(list_of_unique_states)\n",
    "            elif name == 'pi':\n",
    "                pi = val(list_of_unique_states)\n",
    "            else:\n",
    "                continue\n",
    "    \n",
    "    # this will run if kwargs are provided        \n",
    "    if set_params:\n",
    "        for name, val in set_params:\n",
    "            if name == 'B':\n",
    "                B = generate_emission_prob_dist(list_of_unique_states, sequence, **val)\n",
    "            elif name == 'A':\n",
    "                A = generate_state_trans_dict(list_of_unique_states, **val)\n",
    "            elif name == 'pi':\n",
    "                pi = generate_init_prob_dist(list_of_unique_states, **val)\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "    # instantiate the data structure\n",
    "    obs_probs = generate_obs_data_structure(sequence)\n",
    "\n",
    "    # all state transitions\n",
    "    state_perms = make_state_permutations(list_of_unique_states)\n",
    "\n",
    "    # for every transition from one observation to the next, calculate probability of going from Si to Sj\n",
    "    # loop through observations\n",
    "    for idx, obs in enumerate(sequence):\n",
    "\n",
    "        if idx != 0:  # check if this is the first observation\n",
    "            # instantiate the namedtuple for this observation\n",
    "            obs_probs[idx] = obs_probs[idx]([], [], [])\n",
    "\n",
    "            # loop through each possible state transition\n",
    "            for st in state_perms:\n",
    "                \n",
    "                # calculate prob of current obs for this state\n",
    "                prev_prob = pi[st[:2]] * B[st[:2]+'_'+str(sequence[idx-1])]\n",
    "\n",
    "                # calculate prob of previous obs for this state\n",
    "                curr_prob = A[st] * B[st[2:]+'_'+str(obs)]\n",
    "\n",
    "                # combine these two probabilities\n",
    "                combined_prob = round(curr_prob * prev_prob, 4)\n",
    "\n",
    "                # append probability to the list in namedtuple\n",
    "                obs_probs[idx].prob_lst.append(combined_prob)\n",
    "\n",
    "            # check for highest prob of observing that sequence\n",
    "            prob_and_state = _grab_highest_prob_and_state(state_perms, obs_probs[idx].prob_lst)\n",
    "            obs_probs[idx].highest_prob.append(prob_and_state[0])\n",
    "            obs_probs[idx].highest_state.append(prob_and_state[1])\n",
    "\n",
    "        else: # this is the first observation, exit loop.\n",
    "            continue\n",
    "    return (obs_probs, A, B, pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "ob_prob, A, B, pi = calculate_probabilities(STATE_LIST, corn13_17_seq, A=A_prior, B=B_prior, pi=pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: ObservationData(prob_lst=[0.0144, 0.0144, 0.0126, 0.0132], highest_prob=[0.0144], highest_state=['S1S1']),\n",
       " 2: ObservationData(prob_lst=[0.0144, 0.0144, 0.0126, 0.0132], highest_prob=[0.0144], highest_state=['S1S1']),\n",
       " 3: ObservationData(prob_lst=[0.0144, 0.0144, 0.0126, 0.0132], highest_prob=[0.0144], highest_state=['S1S1']),\n",
       " 4: ObservationData(prob_lst=[0.0144, 0.0144, 0.0126, 0.0132], highest_prob=[0.0144], highest_state=['S1S1']),\n",
       " 5: ObservationData(prob_lst=[0.0144, 0.0144, 0.0126, 0.0132], highest_prob=[0.0144], highest_state=['S1S1']),\n",
       " 6: ObservationData(prob_lst=[0.0144, 0.0144, 0.0126, 0.0132], highest_prob=[0.0144], highest_state=['S1S1']),\n",
       " 7: ObservationData(prob_lst=[0.0144, 0.0144, 0.0126, 0.0132], highest_prob=[0.0144], highest_state=['S1S1']),\n",
       " 8: ObservationData(prob_lst=[0.0144, 0.0144, 0.0126, 0.0132], highest_prob=[0.0144], highest_state=['S1S1']),\n",
       " 9: ObservationData(prob_lst=[0.0144, 0.0144, 0.0126, 0.0132], highest_prob=[0.0144], highest_state=['S1S1']),\n",
       " 10: ObservationData(prob_lst=[0.0144, 0.0144, 0.0126, 0.0132], highest_prob=[0.0144], highest_state=['S1S1']),\n",
       " 11: ObservationData(prob_lst=[0.0144, 0.0144, 0.0126, 0.0132], highest_prob=[0.0144], highest_state=['S1S1']),\n",
       " 12: ObservationData(prob_lst=[0.0144, 0.0144, 0.0126, 0.0132], highest_prob=[0.0144], highest_state=['S1S1']),\n",
       " 13: ObservationData(prob_lst=[0.0144, 0.0144, 0.0126, 0.0132], highest_prob=[0.0144], highest_state=['S1S1']),\n",
       " 14: ObservationData(prob_lst=[0.0144, 0.0144, 0.0126, 0.0132], highest_prob=[0.0144], highest_state=['S1S1']),\n",
       " 15: ObservationData(prob_lst=[0.0144, 0.0144, 0.0126, 0.0132], highest_prob=[0.0144], highest_state=['S1S1']),\n",
       " 16: ObservationData(prob_lst=[0.0144, 0.0144, 0.0126, 0.0132], highest_prob=[0.0144], highest_state=['S1S1']),\n",
       " 17: ObservationData(prob_lst=[0.0144, 0.0144, 0.0126, 0.0132], highest_prob=[0.0144], highest_state=['S1S1']),\n",
       " 18: ObservationData(prob_lst=[0.0144, 0.0144, 0.0126, 0.0132], highest_prob=[0.0144], highest_state=['S1S1']),\n",
       " 19: ObservationData(prob_lst=[0.0144, 0.0144, 0.0126, 0.0132], highest_prob=[0.0144], highest_state=['S1S1']),\n",
       " 20: ObservationData(prob_lst=[0.0144, 0.0144, 0.0126, 0.0132], highest_prob=[0.0144], highest_state=['S1S1']),\n",
       " 21: ObservationData(prob_lst=[0.0144, 0.0144, 0.0126, 0.0132], highest_prob=[0.0144], highest_state=['S1S1']),\n",
       " 22: ObservationData(prob_lst=[0.0144, 0.0144, 0.0126, 0.0132], highest_prob=[0.0144], highest_state=['S1S1']),\n",
       " 23: ObservationData(prob_lst=[0.0144, 0.0144, 0.0126, 0.0132], highest_prob=[0.0144], highest_state=['S1S1']),\n",
       " 24: ObservationData(prob_lst=[0.0144, 0.0144, 0.0126, 0.0132], highest_prob=[0.0144], highest_state=['S1S1']),\n",
       " 25: ObservationData(prob_lst=[0.0144, 0.0144, 0.0126, 0.0132], highest_prob=[0.0144], highest_state=['S1S1']),\n",
       " 26: ObservationData(prob_lst=[0.0192, 0.0216, 0.0168, 0.0198], highest_prob=[0.0216], highest_state=['S1S2']),\n",
       " 27: ObservationData(prob_lst=[0.0192, 0.0192, 0.0189, 0.0198], highest_prob=[0.0198], highest_state=['S2S2']),\n",
       " 28: ObservationData(prob_lst=[0.0192, 0.0216, 0.0168, 0.0198], highest_prob=[0.0216], highest_state=['S1S2']),\n",
       " 29: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 30: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 31: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 32: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 33: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 34: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 35: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 36: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 37: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 38: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 39: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 40: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 41: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 42: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 43: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 44: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 45: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 46: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 47: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 48: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 49: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 50: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 51: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 52: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 53: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 54: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 55: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 56: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 57: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 58: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 59: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 60: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 61: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 62: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 63: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 64: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 65: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 66: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 67: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 68: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 69: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 70: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 71: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 72: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 73: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 74: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 75: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 76: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 77: ObservationData(prob_lst=[0.0256, 0.0288, 0.0252, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 78: ObservationData(prob_lst=[0.0096, 0.0048, 0.0095, 0.005], highest_prob=[0.0096], highest_state=['S1S1']),\n",
       " 79: ObservationData(prob_lst=[0.0036, 0.0018, 0.0016, 0.0008], highest_prob=[0.0036], highest_state=['S1S1']),\n",
       " 80: ObservationData(prob_lst=[0.0036, 0.0018, 0.0016, 0.0008], highest_prob=[0.0036], highest_state=['S1S1']),\n",
       " 81: ObservationData(prob_lst=[0.0036, 0.0018, 0.0016, 0.0008], highest_prob=[0.0036], highest_state=['S1S1']),\n",
       " 82: ObservationData(prob_lst=[0.0036, 0.0018, 0.0016, 0.0008], highest_prob=[0.0036], highest_state=['S1S1']),\n",
       " 83: ObservationData(prob_lst=[0.0036, 0.0018, 0.0016, 0.0008], highest_prob=[0.0036], highest_state=['S1S1']),\n",
       " 84: ObservationData(prob_lst=[0.0036, 0.0018, 0.0016, 0.0008], highest_prob=[0.0036], highest_state=['S1S1']),\n",
       " 85: ObservationData(prob_lst=[0.0036, 0.0018, 0.0016, 0.0008], highest_prob=[0.0036], highest_state=['S1S1']),\n",
       " 86: ObservationData(prob_lst=[0.0036, 0.0018, 0.0016, 0.0008], highest_prob=[0.0036], highest_state=['S1S1']),\n",
       " 87: ObservationData(prob_lst=[0.0036, 0.0018, 0.0016, 0.0008], highest_prob=[0.0036], highest_state=['S1S1']),\n",
       " 88: ObservationData(prob_lst=[0.0024, 0.0054, 0.001, 0.0025], highest_prob=[0.0054], highest_state=['S1S2']),\n",
       " 89: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 90: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 91: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 92: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 93: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 94: ObservationData(prob_lst=[0.0024, 0.0012, 0.0047, 0.0025], highest_prob=[0.0047], highest_state=['S2S1']),\n",
       " 95: ObservationData(prob_lst=[0.0036, 0.0018, 0.0016, 0.0008], highest_prob=[0.0036], highest_state=['S1S1']),\n",
       " 96: ObservationData(prob_lst=[0.0036, 0.0018, 0.0016, 0.0008], highest_prob=[0.0036], highest_state=['S1S1']),\n",
       " 97: ObservationData(prob_lst=[0.0036, 0.0018, 0.0016, 0.0008], highest_prob=[0.0036], highest_state=['S1S1']),\n",
       " 98: ObservationData(prob_lst=[0.0036, 0.0018, 0.0016, 0.0008], highest_prob=[0.0036], highest_state=['S1S1']),\n",
       " 99: ObservationData(prob_lst=[0.0036, 0.0018, 0.0016, 0.0008], highest_prob=[0.0036], highest_state=['S1S1']),\n",
       " 100: ObservationData(prob_lst=[0.0036, 0.0018, 0.0016, 0.0008], highest_prob=[0.0036], highest_state=['S1S1']),\n",
       " 101: ObservationData(prob_lst=[0.0036, 0.0018, 0.0016, 0.0008], highest_prob=[0.0036], highest_state=['S1S1']),\n",
       " 102: ObservationData(prob_lst=[0.0036, 0.0018, 0.0016, 0.0008], highest_prob=[0.0036], highest_state=['S1S1']),\n",
       " 103: ObservationData(prob_lst=[0.0036, 0.0018, 0.0016, 0.0008], highest_prob=[0.0036], highest_state=['S1S1']),\n",
       " 104: ObservationData(prob_lst=[0.0036, 0.0018, 0.0016, 0.0008], highest_prob=[0.0036], highest_state=['S1S1']),\n",
       " 105: ObservationData(prob_lst=[0.0036, 0.0018, 0.0016, 0.0008], highest_prob=[0.0036], highest_state=['S1S1']),\n",
       " 106: ObservationData(prob_lst=[0.0036, 0.0018, 0.0016, 0.0008], highest_prob=[0.0036], highest_state=['S1S1']),\n",
       " 107: ObservationData(prob_lst=[0.0036, 0.0018, 0.0016, 0.0008], highest_prob=[0.0036], highest_state=['S1S1']),\n",
       " 108: ObservationData(prob_lst=[0.0036, 0.0018, 0.0016, 0.0008], highest_prob=[0.0036], highest_state=['S1S1']),\n",
       " 109: ObservationData(prob_lst=[0.0036, 0.0018, 0.0016, 0.0008], highest_prob=[0.0036], highest_state=['S1S1']),\n",
       " 110: ObservationData(prob_lst=[0.0036, 0.0018, 0.0016, 0.0008], highest_prob=[0.0036], highest_state=['S1S1']),\n",
       " 111: ObservationData(prob_lst=[0.0036, 0.0018, 0.0016, 0.0008], highest_prob=[0.0036], highest_state=['S1S1']),\n",
       " 112: ObservationData(prob_lst=[0.0036, 0.0018, 0.0016, 0.0008], highest_prob=[0.0036], highest_state=['S1S1']),\n",
       " 113: ObservationData(prob_lst=[0.0036, 0.0018, 0.0016, 0.0008], highest_prob=[0.0036], highest_state=['S1S1']),\n",
       " 114: ObservationData(prob_lst=[0.0036, 0.0018, 0.0016, 0.0008], highest_prob=[0.0036], highest_state=['S1S1']),\n",
       " 115: ObservationData(prob_lst=[0.0036, 0.0018, 0.0016, 0.0008], highest_prob=[0.0036], highest_state=['S1S1']),\n",
       " 116: ObservationData(prob_lst=[0.0036, 0.0018, 0.0016, 0.0008], highest_prob=[0.0036], highest_state=['S1S1']),\n",
       " 117: ObservationData(prob_lst=[0.0036, 0.0018, 0.0016, 0.0008], highest_prob=[0.0036], highest_state=['S1S1']),\n",
       " 118: ObservationData(prob_lst=[0.0036, 0.0018, 0.0016, 0.0008], highest_prob=[0.0036], highest_state=['S1S1']),\n",
       " 119: ObservationData(prob_lst=[0.0036, 0.0018, 0.0016, 0.0008], highest_prob=[0.0036], highest_state=['S1S1']),\n",
       " 120: ObservationData(prob_lst=[0.0024, 0.0054, 0.001, 0.0025], highest_prob=[0.0054], highest_state=['S1S2']),\n",
       " 121: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 122: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 123: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 124: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 125: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 126: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 127: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 128: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 129: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 130: ObservationData(prob_lst=[0.0024, 0.0012, 0.0047, 0.0025], highest_prob=[0.0047], highest_state=['S2S1']),\n",
       " 131: ObservationData(prob_lst=[0.0036, 0.0018, 0.0016, 0.0008], highest_prob=[0.0036], highest_state=['S1S1']),\n",
       " 132: ObservationData(prob_lst=[0.0036, 0.0018, 0.0016, 0.0008], highest_prob=[0.0036], highest_state=['S1S1']),\n",
       " 133: ObservationData(prob_lst=[0.0036, 0.0018, 0.0016, 0.0008], highest_prob=[0.0036], highest_state=['S1S1']),\n",
       " 134: ObservationData(prob_lst=[0.0024, 0.0054, 0.001, 0.0025], highest_prob=[0.0054], highest_state=['S1S2']),\n",
       " 135: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 136: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 137: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 138: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 139: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 140: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 141: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 142: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 143: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 144: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 145: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 146: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 147: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 148: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 149: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 150: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 151: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 152: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 153: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 154: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 155: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 156: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 157: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 158: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 159: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 160: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 161: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 162: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 163: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 164: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 165: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 166: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 167: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 168: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 169: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 170: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 171: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 172: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 173: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 174: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 175: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 176: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 177: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 178: ObservationData(prob_lst=[0.0024, 0.0012, 0.0047, 0.0025], highest_prob=[0.0047], highest_state=['S2S1']),\n",
       " 179: ObservationData(prob_lst=[0.0036, 0.0018, 0.0016, 0.0008], highest_prob=[0.0036], highest_state=['S1S1']),\n",
       " 180: ObservationData(prob_lst=[0.0036, 0.0018, 0.0016, 0.0008], highest_prob=[0.0036], highest_state=['S1S1']),\n",
       " 181: ObservationData(prob_lst=[0.0024, 0.0054, 0.001, 0.0025], highest_prob=[0.0054], highest_state=['S1S2']),\n",
       " 182: ObservationData(prob_lst=[0.0016, 0.0036, 0.0031, 0.0074], highest_prob=[0.0074], highest_state=['S2S2']),\n",
       " 183: ObservationData(prob_lst=[0.0008, 0.0072, 0.0016, 0.0149], highest_prob=[0.0149], highest_state=['S2S2']),\n",
       " 184: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 185: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 186: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 187: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 188: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 189: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 190: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 191: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 192: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 193: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 194: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 195: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 196: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 197: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 198: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 199: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 200: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 201: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 202: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 203: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 204: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 205: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 206: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 207: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 208: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 209: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 210: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 211: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 212: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 213: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 214: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 215: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 216: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 217: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 218: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 219: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 220: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 221: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 222: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 223: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 224: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 225: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 226: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 227: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 228: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 229: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 230: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 231: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 232: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 233: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 234: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 235: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 236: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 237: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 238: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 239: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 240: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 241: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 242: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 243: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 244: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 245: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 246: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2']),\n",
       " 247: ObservationData(prob_lst=[0.0004, 0.0036, 0.0031, 0.0297], highest_prob=[0.0297], highest_state=['S2S2'])}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ob_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S1S1': 0.4, 'S1S2': 0.6, 'S2S1': 0.35, 'S2S2': 0.55}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S1_0': 0.1,\n",
       " 'S1_1': 0.3,\n",
       " 'S1_2': 0.4,\n",
       " 'S1_3': 0.15,\n",
       " 'S1_4': 0.05,\n",
       " 'S2_0': 0.15,\n",
       " 'S2_1': 0.2,\n",
       " 'S2_2': 0.3,\n",
       " 'S2_3': 0.05,\n",
       " 'S2_4': 0.3}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S1': 0.4, 'S2': 0.6}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### STEP 2: UPDATE PARAMETERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Update the State Transition Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This function sums all of the probabilities and \n",
    "# outputs a new (un-normalized) state transition matrix\n",
    "def new_state_trans(STATE_LIST, probabilities):\n",
    "    state_perms = make_state_permutations(STATE_LIST)\n",
    "    sums_of_st_trans_prob = {p:0 for p in state_perms}\n",
    "    highest_prob_sum = 0\n",
    "    for obs in probabilities:\n",
    "        highest_prob_sum += probabilities[obs].highest_prob[0]\n",
    "        for i, p in enumerate(sums_of_st_trans_prob):\n",
    "            sums_of_st_trans_prob[p] += probabilities[obs].prob_lst[i]\n",
    "    \n",
    "    for key in sums_of_st_trans_prob:\n",
    "        sums_of_st_trans_prob[key] = sums_of_st_trans_prob[key] / highest_prob_sum\n",
    "    \n",
    "    # finally, normalize so the rows add up to 1\n",
    "    for s in STATE_LIST:\n",
    "        l = []\n",
    "        for k in sums_of_st_trans_prob:\n",
    "            if s == k[:2]:\n",
    "                l.append(sums_of_st_trans_prob[k])\n",
    "        for k in sums_of_st_trans_prob:\n",
    "            if s == k[:2]:\n",
    "                sums_of_st_trans_prob[k] = sums_of_st_trans_prob[k] / sum(l)\n",
    "    \n",
    "    return sums_of_st_trans_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S1S1': 0.45133926513300415,\n",
       " 'S1S2': 0.5486607348669958,\n",
       " 'S2S1': 0.3281027330018689,\n",
       " 'S2S2': 0.6718972669981311}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update and normalize posterior state transition\n",
    "A_posterior = new_state_trans(STATE_LIST, ob_prob)\n",
    "A_posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Convert state transition to \"format 2\" so it can be\n",
    "# used as input in the next iteration of \"E\" step\n",
    "A_posterior = dict_to_tuples(STATE_LIST, A_posterior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Update the Emission Probabilities**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Here, we define some functions designed to do specific tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "##### tally up all observed sequences\n",
    "def observed_pairs(sequence):\n",
    "    observed_pairs = []\n",
    "    for idx in range(len(sequence)-1):\n",
    "        observed_pairs.append((sequence[idx], sequence[idx+1]))\n",
    "    return observed_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0), (0, 1), (0, 3), (1, 0), (1, 1), (1, 3), (3, 0), (3, 1), (3, 3)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_emission_permutations(sequence):\n",
    "    unique_e = np.unique(sequence)\n",
    "    return list(product(unique_e, repeat = 2))\n",
    "\n",
    "make_emission_permutations([1,1,0, 2])\n",
    "make_emission_permutations([0,1,0,3,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def find_highest_with_state_obs(prob_pairs, state, obs):\n",
    "    for pp in prob_pairs:\n",
    "        if pp[0].count((state,obs))>0:\n",
    "            return pp[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def normalize_emissions(b_tuple_format):\n",
    "    new_b_dict = {}\n",
    "    for key, val in b_tuple_format.items():\n",
    "        denominator = sum(val)\n",
    "        new_lst = [v/denominator for v in val]\n",
    "        new_b_dict[key] = tuple(new_lst)\n",
    "    return new_b_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Finally, we are ready to update the emission probabilities with the function below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def emission_matrix_update(sequence, state_list, A, B, pi):\n",
    "    state_pairs = list(product(state_list, repeat = 2))\n",
    "    obs_pairs = observed_pairs(sequence)\n",
    "    \n",
    "    new_B = {}\n",
    "    for obs in np.unique(sequence): # For every unique emission\n",
    "        \n",
    "        # Find all the sequence-pairs that include that emission\n",
    "        inc_seq = [seq for seq in obs_pairs if seq.count(obs)>0]\n",
    "\n",
    "        # Collector for highest-probabilities\n",
    "        highest_pairs = []\n",
    "        \n",
    "        # For each sequence-pair that include that emission\n",
    "        for seq in inc_seq:\n",
    "\n",
    "            prob_pairs = []\n",
    "            \n",
    "            # Go through each potential pair of states\n",
    "            for state_pair in state_pairs:\n",
    "                \n",
    "                state1, state2 = state_pair\n",
    "                obs1, obs2 = seq\n",
    "                \n",
    "                # Match each state with it's emission\n",
    "                assoc_tuples = [(state1, obs1),\n",
    "                                (state2, obs2)]\n",
    "                \n",
    "                # Calculate the probability of the sequence from state\n",
    "                prob = pi[state1] * B[state1+\"_\"+str(obs1)]\n",
    "                prob *= A[state1+state2]*B[state2+\"_\"+str(obs2)]\n",
    "                prob = round(prob,5)\n",
    "                # Append the state emission tuples and probability\n",
    "                prob_pairs.append([assoc_tuples, prob])\n",
    "    \n",
    "            # Sort probabilities by maximum probability\n",
    "            prob_pairs = sorted(prob_pairs, key = lambda x: x[1], reverse = True)\n",
    "            \n",
    "            # Save the highest probability\n",
    "            to_add = {'highest':prob_pairs[0][1]}\n",
    "            # Find the highest probability where each state is associated\n",
    "            # With the current emission\n",
    "            for state in STATE_LIST:\n",
    "                \n",
    "                highest_of_state = 0\n",
    "                \n",
    "                # Go through sorted list, find first (state,observation) tuple\n",
    "                # save associated probability\n",
    "\n",
    "                for pp in prob_pairs:\n",
    "                    if pp[0].count((state,obs))>0:\n",
    "                        highest_of_state = pp[1]\n",
    "                        break\n",
    "                        \n",
    "                to_add[state] = highest_of_state\n",
    "            \n",
    "            # Save completed dictionary\n",
    "            highest_pairs.append(to_add)\n",
    "        \n",
    "        # Total highest_probability\n",
    "        highest_probability =sum([d['highest'] for d in highest_pairs])\n",
    "        \n",
    "        # Total highest probabilities for each state; divide by highest prob\n",
    "        # Add to new emission matrix\n",
    "        for state in STATE_LIST:\n",
    "            new_B[state+\"_\"+str(obs)]= sum([d[state] for d in highest_pairs])/highest_probability\n",
    "            \n",
    "        \n",
    "    return new_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Run the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S1_0': 0.483408779434362,\n",
       " 'S2_0': 1.0,\n",
       " 'S1_1': 0.9985815602836879,\n",
       " 'S2_1': 0.9914893617021275,\n",
       " 'S1_2': 0.9676025917926563,\n",
       " 'S2_2': 0.9999018260357353,\n",
       " 'S1_3': 1.0,\n",
       " 'S2_3': 0.49792776791000587,\n",
       " 'S1_4': 0.12109205752616592,\n",
       " 'S2_4': 1.0}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = emission_matrix_update(corn13_17_seq,STATE_LIST, A,B,pi)\n",
    "nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The emission probabilities are updated, but they need to be normalized. To do this, we will convert to dictionary to the `key: tuple` format and normalize so that the probabilities add up to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "B_ = obs_to_tuples(STATE_LIST, nb, corn13_17_seq)\n",
    "B_posterior = normalize_emissions(B_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S1': (0.45133926513300415, 0.5486607348669958),\n",
       " 'S2': (0.3281027330018689, 0.6718972669981311)}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalized state transition posterior:\n",
    "A_posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S1': (0.13538264532395863,\n",
       "  0.2796610631712537,\n",
       "  0.2709851456411028,\n",
       "  0.280058308999622,\n",
       "  0.03391283686406297),\n",
       " 'S2': (0.22275093613964136,\n",
       "  0.2208551834916444,\n",
       "  0.22272906779719687,\n",
       "  0.11091387643187589,\n",
       "  0.22275093613964136)}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalized emission posterior probabilities\n",
    "B_posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### STEP 3: REPEAT UNTIL PARAMETERS CONVERGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: ObservationData(prob_lst=[0.0141, 0.0136, 0.0122, 0.0197], highest_prob=[0.0197], highest_state=['S2S2']),\n",
       " 2: ObservationData(prob_lst=[0.0141, 0.0136, 0.0122, 0.0197], highest_prob=[0.0197], highest_state=['S2S2']),\n",
       " 3: ObservationData(prob_lst=[0.0141, 0.0136, 0.0122, 0.0197], highest_prob=[0.0197], highest_state=['S2S2']),\n",
       " 4: ObservationData(prob_lst=[0.0141, 0.0136, 0.0122, 0.0197], highest_prob=[0.0197], highest_state=['S2S2']),\n",
       " 5: ObservationData(prob_lst=[0.0141, 0.0136, 0.0122, 0.0197], highest_prob=[0.0197], highest_state=['S2S2']),\n",
       " 6: ObservationData(prob_lst=[0.0141, 0.0136, 0.0122, 0.0197], highest_prob=[0.0197], highest_state=['S2S2']),\n",
       " 7: ObservationData(prob_lst=[0.0141, 0.0136, 0.0122, 0.0197], highest_prob=[0.0197], highest_state=['S2S2']),\n",
       " 8: ObservationData(prob_lst=[0.0141, 0.0136, 0.0122, 0.0197], highest_prob=[0.0197], highest_state=['S2S2']),\n",
       " 9: ObservationData(prob_lst=[0.0141, 0.0136, 0.0122, 0.0197], highest_prob=[0.0197], highest_state=['S2S2']),\n",
       " 10: ObservationData(prob_lst=[0.0141, 0.0136, 0.0122, 0.0197], highest_prob=[0.0197], highest_state=['S2S2']),\n",
       " 11: ObservationData(prob_lst=[0.0141, 0.0136, 0.0122, 0.0197], highest_prob=[0.0197], highest_state=['S2S2']),\n",
       " 12: ObservationData(prob_lst=[0.0141, 0.0136, 0.0122, 0.0197], highest_prob=[0.0197], highest_state=['S2S2']),\n",
       " 13: ObservationData(prob_lst=[0.0141, 0.0136, 0.0122, 0.0197], highest_prob=[0.0197], highest_state=['S2S2']),\n",
       " 14: ObservationData(prob_lst=[0.0141, 0.0136, 0.0122, 0.0197], highest_prob=[0.0197], highest_state=['S2S2']),\n",
       " 15: ObservationData(prob_lst=[0.0141, 0.0136, 0.0122, 0.0197], highest_prob=[0.0197], highest_state=['S2S2']),\n",
       " 16: ObservationData(prob_lst=[0.0141, 0.0136, 0.0122, 0.0197], highest_prob=[0.0197], highest_state=['S2S2']),\n",
       " 17: ObservationData(prob_lst=[0.0141, 0.0136, 0.0122, 0.0197], highest_prob=[0.0197], highest_state=['S2S2']),\n",
       " 18: ObservationData(prob_lst=[0.0141, 0.0136, 0.0122, 0.0197], highest_prob=[0.0197], highest_state=['S2S2']),\n",
       " 19: ObservationData(prob_lst=[0.0141, 0.0136, 0.0122, 0.0197], highest_prob=[0.0197], highest_state=['S2S2']),\n",
       " 20: ObservationData(prob_lst=[0.0141, 0.0136, 0.0122, 0.0197], highest_prob=[0.0197], highest_state=['S2S2']),\n",
       " 21: ObservationData(prob_lst=[0.0141, 0.0136, 0.0122, 0.0197], highest_prob=[0.0197], highest_state=['S2S2']),\n",
       " 22: ObservationData(prob_lst=[0.0141, 0.0136, 0.0122, 0.0197], highest_prob=[0.0197], highest_state=['S2S2']),\n",
       " 23: ObservationData(prob_lst=[0.0141, 0.0136, 0.0122, 0.0197], highest_prob=[0.0197], highest_state=['S2S2']),\n",
       " 24: ObservationData(prob_lst=[0.0141, 0.0136, 0.0122, 0.0197], highest_prob=[0.0197], highest_state=['S2S2']),\n",
       " 25: ObservationData(prob_lst=[0.0141, 0.0136, 0.0122, 0.0197], highest_prob=[0.0197], highest_state=['S2S2']),\n",
       " 26: ObservationData(prob_lst=[0.0137, 0.0137, 0.0118, 0.0198], highest_prob=[0.0198], highest_state=['S2S2']),\n",
       " 27: ObservationData(prob_lst=[0.0137, 0.0131, 0.0123, 0.0198], highest_prob=[0.0198], highest_state=['S2S2']),\n",
       " 28: ObservationData(prob_lst=[0.0137, 0.0137, 0.0118, 0.0198], highest_prob=[0.0198], highest_state=['S2S2']),\n",
       " 29: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 30: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 31: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 32: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 33: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 34: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 35: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 36: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 37: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 38: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 39: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 40: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 41: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 42: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 43: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 44: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 45: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 46: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 47: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 48: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 49: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 50: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 51: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 52: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 53: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 54: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 55: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 56: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 57: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 58: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 59: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 60: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 61: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 62: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 63: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 64: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 65: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 66: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 67: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 68: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 69: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 70: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 71: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 72: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 73: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 74: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 75: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 76: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 77: ObservationData(prob_lst=[0.0133, 0.0132, 0.0119, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 78: ObservationData(prob_lst=[0.0137, 0.0066, 0.0123, 0.01], highest_prob=[0.0137], highest_state=['S1S1']),\n",
       " 79: ObservationData(prob_lst=[0.0142, 0.0068, 0.0061, 0.005], highest_prob=[0.0142], highest_state=['S1S1']),\n",
       " 80: ObservationData(prob_lst=[0.0142, 0.0068, 0.0061, 0.005], highest_prob=[0.0142], highest_state=['S1S1']),\n",
       " 81: ObservationData(prob_lst=[0.0142, 0.0068, 0.0061, 0.005], highest_prob=[0.0142], highest_state=['S1S1']),\n",
       " 82: ObservationData(prob_lst=[0.0142, 0.0068, 0.0061, 0.005], highest_prob=[0.0142], highest_state=['S1S1']),\n",
       " 83: ObservationData(prob_lst=[0.0142, 0.0068, 0.0061, 0.005], highest_prob=[0.0142], highest_state=['S1S1']),\n",
       " 84: ObservationData(prob_lst=[0.0142, 0.0068, 0.0061, 0.005], highest_prob=[0.0142], highest_state=['S1S1']),\n",
       " 85: ObservationData(prob_lst=[0.0142, 0.0068, 0.0061, 0.005], highest_prob=[0.0142], highest_state=['S1S1']),\n",
       " 86: ObservationData(prob_lst=[0.0142, 0.0068, 0.0061, 0.005], highest_prob=[0.0142], highest_state=['S1S1']),\n",
       " 87: ObservationData(prob_lst=[0.0142, 0.0068, 0.0061, 0.005], highest_prob=[0.0142], highest_state=['S1S1']),\n",
       " 88: ObservationData(prob_lst=[0.0068, 0.0137, 0.003, 0.01], highest_prob=[0.0137], highest_state=['S1S2']),\n",
       " 89: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 90: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 91: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 92: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 93: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 94: ObservationData(prob_lst=[0.0068, 0.0033, 0.0123, 0.01], highest_prob=[0.0123], highest_state=['S2S1']),\n",
       " 95: ObservationData(prob_lst=[0.0142, 0.0068, 0.0061, 0.005], highest_prob=[0.0142], highest_state=['S1S1']),\n",
       " 96: ObservationData(prob_lst=[0.0142, 0.0068, 0.0061, 0.005], highest_prob=[0.0142], highest_state=['S1S1']),\n",
       " 97: ObservationData(prob_lst=[0.0142, 0.0068, 0.0061, 0.005], highest_prob=[0.0142], highest_state=['S1S1']),\n",
       " 98: ObservationData(prob_lst=[0.0142, 0.0068, 0.0061, 0.005], highest_prob=[0.0142], highest_state=['S1S1']),\n",
       " 99: ObservationData(prob_lst=[0.0142, 0.0068, 0.0061, 0.005], highest_prob=[0.0142], highest_state=['S1S1']),\n",
       " 100: ObservationData(prob_lst=[0.0142, 0.0068, 0.0061, 0.005], highest_prob=[0.0142], highest_state=['S1S1']),\n",
       " 101: ObservationData(prob_lst=[0.0142, 0.0068, 0.0061, 0.005], highest_prob=[0.0142], highest_state=['S1S1']),\n",
       " 102: ObservationData(prob_lst=[0.0142, 0.0068, 0.0061, 0.005], highest_prob=[0.0142], highest_state=['S1S1']),\n",
       " 103: ObservationData(prob_lst=[0.0142, 0.0068, 0.0061, 0.005], highest_prob=[0.0142], highest_state=['S1S1']),\n",
       " 104: ObservationData(prob_lst=[0.0142, 0.0068, 0.0061, 0.005], highest_prob=[0.0142], highest_state=['S1S1']),\n",
       " 105: ObservationData(prob_lst=[0.0142, 0.0068, 0.0061, 0.005], highest_prob=[0.0142], highest_state=['S1S1']),\n",
       " 106: ObservationData(prob_lst=[0.0142, 0.0068, 0.0061, 0.005], highest_prob=[0.0142], highest_state=['S1S1']),\n",
       " 107: ObservationData(prob_lst=[0.0142, 0.0068, 0.0061, 0.005], highest_prob=[0.0142], highest_state=['S1S1']),\n",
       " 108: ObservationData(prob_lst=[0.0142, 0.0068, 0.0061, 0.005], highest_prob=[0.0142], highest_state=['S1S1']),\n",
       " 109: ObservationData(prob_lst=[0.0142, 0.0068, 0.0061, 0.005], highest_prob=[0.0142], highest_state=['S1S1']),\n",
       " 110: ObservationData(prob_lst=[0.0142, 0.0068, 0.0061, 0.005], highest_prob=[0.0142], highest_state=['S1S1']),\n",
       " 111: ObservationData(prob_lst=[0.0142, 0.0068, 0.0061, 0.005], highest_prob=[0.0142], highest_state=['S1S1']),\n",
       " 112: ObservationData(prob_lst=[0.0142, 0.0068, 0.0061, 0.005], highest_prob=[0.0142], highest_state=['S1S1']),\n",
       " 113: ObservationData(prob_lst=[0.0142, 0.0068, 0.0061, 0.005], highest_prob=[0.0142], highest_state=['S1S1']),\n",
       " 114: ObservationData(prob_lst=[0.0142, 0.0068, 0.0061, 0.005], highest_prob=[0.0142], highest_state=['S1S1']),\n",
       " 115: ObservationData(prob_lst=[0.0142, 0.0068, 0.0061, 0.005], highest_prob=[0.0142], highest_state=['S1S1']),\n",
       " 116: ObservationData(prob_lst=[0.0142, 0.0068, 0.0061, 0.005], highest_prob=[0.0142], highest_state=['S1S1']),\n",
       " 117: ObservationData(prob_lst=[0.0142, 0.0068, 0.0061, 0.005], highest_prob=[0.0142], highest_state=['S1S1']),\n",
       " 118: ObservationData(prob_lst=[0.0142, 0.0068, 0.0061, 0.005], highest_prob=[0.0142], highest_state=['S1S1']),\n",
       " 119: ObservationData(prob_lst=[0.0142, 0.0068, 0.0061, 0.005], highest_prob=[0.0142], highest_state=['S1S1']),\n",
       " 120: ObservationData(prob_lst=[0.0068, 0.0137, 0.003, 0.01], highest_prob=[0.0137], highest_state=['S1S2']),\n",
       " 121: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 122: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 123: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 124: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 125: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 126: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 127: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 128: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 129: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 130: ObservationData(prob_lst=[0.0068, 0.0033, 0.0123, 0.01], highest_prob=[0.0123], highest_state=['S2S1']),\n",
       " 131: ObservationData(prob_lst=[0.0142, 0.0068, 0.0061, 0.005], highest_prob=[0.0142], highest_state=['S1S1']),\n",
       " 132: ObservationData(prob_lst=[0.0142, 0.0068, 0.0061, 0.005], highest_prob=[0.0142], highest_state=['S1S1']),\n",
       " 133: ObservationData(prob_lst=[0.0142, 0.0068, 0.0061, 0.005], highest_prob=[0.0142], highest_state=['S1S1']),\n",
       " 134: ObservationData(prob_lst=[0.0068, 0.0137, 0.003, 0.01], highest_prob=[0.0137], highest_state=['S1S2']),\n",
       " 135: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 136: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 137: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 138: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 139: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 140: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 141: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 142: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 143: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 144: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 145: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 146: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 147: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 148: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 149: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 150: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 151: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 152: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 153: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 154: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 155: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 156: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 157: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 158: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 159: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 160: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 161: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 162: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 163: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 164: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 165: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 166: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 167: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 168: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 169: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 170: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 171: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 172: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 173: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 174: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 175: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 176: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 177: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 178: ObservationData(prob_lst=[0.0068, 0.0033, 0.0123, 0.01], highest_prob=[0.0123], highest_state=['S2S1']),\n",
       " 179: ObservationData(prob_lst=[0.0142, 0.0068, 0.0061, 0.005], highest_prob=[0.0142], highest_state=['S1S1']),\n",
       " 180: ObservationData(prob_lst=[0.0142, 0.0068, 0.0061, 0.005], highest_prob=[0.0142], highest_state=['S1S1']),\n",
       " 181: ObservationData(prob_lst=[0.0068, 0.0137, 0.003, 0.01], highest_prob=[0.0137], highest_state=['S1S2']),\n",
       " 182: ObservationData(prob_lst=[0.0033, 0.0066, 0.0059, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 183: ObservationData(prob_lst=[0.0008, 0.0066, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 184: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 185: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 186: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 187: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 188: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 189: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 190: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 191: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 192: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 193: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 194: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 195: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 196: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 197: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 198: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 199: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 200: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 201: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 202: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 203: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 204: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 205: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 206: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 207: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 208: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 209: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 210: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 211: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 212: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 213: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 214: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 215: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 216: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 217: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 218: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 219: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 220: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 221: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 222: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 223: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 224: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 225: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 226: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 227: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 228: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 229: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 230: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 231: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 232: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 233: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 234: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 235: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 236: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 237: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 238: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 239: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 240: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 241: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 242: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 243: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 244: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 245: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 246: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2']),\n",
       " 247: ObservationData(prob_lst=[0.0002, 0.0017, 0.0015, 0.02], highest_prob=[0.02], highest_state=['S2S2'])}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ob_prob2, A2, B2, pi2 = calculate_probabilities(STATE_LIST, corn13_17_seq, A=A_posterior, B=B_posterior, pi=pi)\n",
    "ob_prob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S1': (0.45133926513300415, 0.5486607348669958),\n",
       " 'S2': (0.3281027330018689, 0.6718972669981311)}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_post2 = new_state_trans(STATE_LIST, ob_prob2)  # update and normalize state transition matrix again\n",
    "A_post2 = dict_to_tuples(STATE_LIST, A2)  # convert to `key: tuple` format\n",
    "A_post2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S1': (0.12264978797133,\n",
       "  0.2543399640652738,\n",
       "  0.23789206342703167,\n",
       "  0.35564606842027513,\n",
       "  0.029472116116089374),\n",
       " 'S2': (0.2210267931381763,\n",
       "  0.2210267931381763,\n",
       "  0.22072878608697358,\n",
       "  0.11619083449849749,\n",
       "  0.2210267931381763)}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update emissions matrix again\n",
    "nb2 = emission_matrix_update(corn13_17_seq, STATE_LIST, A2, B2, pi)  # update emissions matrix again\n",
    "B_post2 = obs_to_tuples(STATE_LIST, nb2, corn13_17_seq)  # convert emission posterior to `key:tuples` format\n",
    "B_post2 = normalize_emissions(B_post2)  # normalize emissions probabilities\n",
    "B_post2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [3.6]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
