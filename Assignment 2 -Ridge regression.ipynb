{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### This cell imports the necessary modules and sets a few plotting parameters for display\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (20.0, 10.0)  \n",
    "\n",
    "### Read in the data\n",
    "\n",
    "data = pd.read_csv('train.csv')  \n",
    "\n",
    "### The .head() function shows the first few lines of data for perspecitve\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "data.plot('GrLivArea', 'SalePrice', kind = 'scatter', marker = 'x');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics \n",
    "\n",
    "def standardize( num_list):\n",
    "    my_array = np.array(num_list)\n",
    "    std= np.std(my_array,axis=0, ddof=0).tolist()\n",
    "    mean= np.mean(my_array).tolist()\n",
    "    norm = [(float(i)-mean)/std for i in num_list]\n",
    "    return norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.11 -1.36 -0.61 -0.61  0.14  0.14  0.88  0.88  0.88  0.88  0.88]\n"
     ]
    }
   ],
   "source": [
    "num_list = [1,2,3,3,4,4,5,5,5,5,5]\n",
    "nl_std = standardize(num_list)\n",
    "print(np.round(nl_std,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_for_regularization(data,y_column_name, x_column_name):\n",
    "    y=data[y_column_name].tolist()\n",
    "    y_mean= np.mean(y).tolist()\n",
    "    norm_y = [(float(i)-y_mean) for i in y]\n",
    "    \n",
    "    a= x_column_name[0]\n",
    "    b= x_column_name[1]\n",
    "    a=data[a].tolist()\n",
    "    b=data[b].tolist()\n",
    "    std_a= np.std(a,axis=0, ddof=0)\n",
    "    mean_a= np.mean(a)\n",
    "    norm_a = [(float(i)-mean_a)/std_a for i in a]\n",
    "    std_b= np.std(b,axis=0, ddof=0)\n",
    "    mean_b= np.mean(b)\n",
    "    norm_b = [(float(i)-mean_b)/std_b for i in b]\n",
    "    dict={\"GrLivArea\":norm_a,'YearBuilt':norm_b,\"sales\":norm_y}\n",
    "    df = pd.DataFrame(dict) \n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.370333</td>\n",
       "      <td>1.050994</td>\n",
       "      <td>27578.80411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.482512</td>\n",
       "      <td>0.156734</td>\n",
       "      <td>578.80411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.515013</td>\n",
       "      <td>0.984752</td>\n",
       "      <td>42578.80411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.383659</td>\n",
       "      <td>-1.863632</td>\n",
       "      <td>-40921.19589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.299326</td>\n",
       "      <td>0.951632</td>\n",
       "      <td>69078.80411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1455</td>\n",
       "      <td>0.250402</td>\n",
       "      <td>0.918511</td>\n",
       "      <td>-5921.19589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1456</td>\n",
       "      <td>1.061367</td>\n",
       "      <td>0.222975</td>\n",
       "      <td>29078.80411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1457</td>\n",
       "      <td>1.569647</td>\n",
       "      <td>-1.002492</td>\n",
       "      <td>85578.80411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1458</td>\n",
       "      <td>-0.832788</td>\n",
       "      <td>-0.704406</td>\n",
       "      <td>-38796.19589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1459</td>\n",
       "      <td>-0.493934</td>\n",
       "      <td>-0.207594</td>\n",
       "      <td>-33421.19589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      GrLivArea  YearBuilt        sales\n",
       "0      0.370333   1.050994  27578.80411\n",
       "1     -0.482512   0.156734    578.80411\n",
       "2      0.515013   0.984752  42578.80411\n",
       "3      0.383659  -1.863632 -40921.19589\n",
       "4      1.299326   0.951632  69078.80411\n",
       "...         ...        ...          ...\n",
       "1455   0.250402   0.918511  -5921.19589\n",
       "1456   1.061367   0.222975  29078.80411\n",
       "1457   1.569647  -1.002492  85578.80411\n",
       "1458  -0.832788  -0.704406 -38796.19589\n",
       "1459  -0.493934  -0.207594 -33421.19589\n",
       "\n",
       "[1460 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_for_regularization(data,'SalePrice', ['GrLivArea','YearBuilt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### Code a function called \"preprocess_for_regularization\" \n",
    "### ACCEPT the DataFrame, a y input and an x input input\n",
    "### RETURN preprocess our data by performing:\n",
    "### -mean subtraction from $y$,\n",
    "### -dimension standardization for $x$\n",
    "\n",
    "### YOUR ANSWER BELOW\n",
    "def preprocess_for_regularization(data,y_column_name, x_column_name):\n",
    "    data_cp = data.copy()\n",
    "    to_return = pd.DataFrame(columns = [y_column_name] + x_column_name)\n",
    "    mean_y = np.mean(data_cp[y_column_name])\n",
    "    to_return[y_column_name] = [x - mean_y for x in data_cp[y_column_name]]\n",
    "    for item in x_column_name:\n",
    "        mean_x = np.mean(data_cp[item])\n",
    "        std_x = np.std(data_cp[item])\n",
    "        to_return[item] = data_cp[item].apply(lambda x: (x - mean_x)/std_x)\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Perform mean subtraction and dimension standardization on data\n",
    "        \n",
    "    Positional argument:\n",
    "        data -- a pandas dataframe of the data to pre-process\n",
    "        y_column_name -- the name (string) of the column that contains\n",
    "            the target of the training data.\n",
    "        x_column_names -- a *list* of the names of columns that contain the\n",
    "            observations to be standardized\n",
    "        \n",
    "    Returns:\n",
    "        Return a DataFrame consisting only of the columns included\n",
    "        in `y_column_name` and `x_column_names`.\n",
    "        Where the y_column has been mean-centered, and the\n",
    "        x_columns have been mean-centered/standardized.\n",
    "        \n",
    "        \n",
    "    Example:\n",
    "        data = pd.read_csv(tr_path).head()\n",
    "        prepro_data = preprocess_for_regularization(data,'SalePrice', ['GrLivArea','YearBuilt'])\n",
    "        \n",
    "        print(prepro_data) #-->\n",
    "                   GrLivArea  YearBuilt  SalePrice\n",
    "                0  -0.082772   0.716753     7800.0\n",
    "                1  -1.590161  -0.089594   -19200.0\n",
    "                2   0.172946   0.657024    22800.0\n",
    "                3  -0.059219  -1.911342   -60700.0\n",
    "                4   1.559205   0.627159    49300.0\n",
    "    \n",
    "    NOTE: The sample standard deviation should be calculated with 0 \"Delta Degrees of Freedom\"\n",
    "    \n",
    "    If your answer does not match the example answer,\n",
    "    check the default degrees of freedom in your standard deviation function.\n",
    "    \"\"\"\n",
    "    return to_return\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>27578.80411</td>\n",
       "      <td>0.370333</td>\n",
       "      <td>1.050994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>578.80411</td>\n",
       "      <td>-0.482512</td>\n",
       "      <td>0.156734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>42578.80411</td>\n",
       "      <td>0.515013</td>\n",
       "      <td>0.984752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-40921.19589</td>\n",
       "      <td>0.383659</td>\n",
       "      <td>-1.863632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>69078.80411</td>\n",
       "      <td>1.299326</td>\n",
       "      <td>0.951632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1455</td>\n",
       "      <td>-5921.19589</td>\n",
       "      <td>0.250402</td>\n",
       "      <td>0.918511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1456</td>\n",
       "      <td>29078.80411</td>\n",
       "      <td>1.061367</td>\n",
       "      <td>0.222975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1457</td>\n",
       "      <td>85578.80411</td>\n",
       "      <td>1.569647</td>\n",
       "      <td>-1.002492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1458</td>\n",
       "      <td>-38796.19589</td>\n",
       "      <td>-0.832788</td>\n",
       "      <td>-0.704406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1459</td>\n",
       "      <td>-33421.19589</td>\n",
       "      <td>-0.493934</td>\n",
       "      <td>-0.207594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SalePrice  GrLivArea  YearBuilt\n",
       "0     27578.80411   0.370333   1.050994\n",
       "1       578.80411  -0.482512   0.156734\n",
       "2     42578.80411   0.515013   0.984752\n",
       "3    -40921.19589   0.383659  -1.863632\n",
       "4     69078.80411   1.299326   0.951632\n",
       "...           ...        ...        ...\n",
       "1455  -5921.19589   0.250402   0.918511\n",
       "1456  29078.80411   1.061367   0.222975\n",
       "1457  85578.80411   1.569647  -1.002492\n",
       "1458 -38796.19589  -0.832788  -0.704406\n",
       "1459 -33421.19589  -0.493934  -0.207594\n",
       "\n",
       "[1460 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepro_data = preprocess_for_regularization(data,'SalePrice', ['GrLivArea','YearBuilt'])\n",
    "prepro_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next, you'll implement the equation for ridge regression using the closed form equation:\n",
    "\n",
    "wRR=(Î»+XTX)âˆ’1XTy\n",
    "wRR=(Î»+XTX)âˆ’1XTy\n",
    " \n",
    "The function will be very similar to the function you wrote for Least Squares Regression with a slightly different matrix to invert.\n",
    "\n",
    "NB: Many numpy matrix functions will be useful. e.g. np.matmul, np.linalg.inv, np.ones, np.transpose, and np.identity.\n",
    "\n",
    "The main change from Least Squares Regression is that  Î»Î»  is a parameter we must set. This is different from the  ww  parameters that we calculate from either closed form or approximation algorithms.\n",
    "\n",
    "We will address tuning parameters such as  Î»Î»  in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### Code a function called \"ridge_regression_weights\"\n",
    "### ACCEPT three inputs:\n",
    "### Two matricies corresponding to the x inputs and y target\n",
    "### and a number (int or float) for the lambda parameter\n",
    "\n",
    "### RETURN a numpy array of regression weights\n",
    "\n",
    "### The following must be accomplished:\n",
    "\n",
    "### Ensure the number of rows of each the X matrix is greater than the number of columns.\n",
    "### ### If not, transpose the matrix.\n",
    "### Ultimately, the y input will have length n.\n",
    "### Thus the x input should be in the shape n-by-p\n",
    "\n",
    "### *Prepend* an n-by-1 column of ones to the input_x matrix\n",
    "\n",
    "### Use the above equation to calculate the least squares weights.\n",
    "### This will involve creating the lambda matrix---\n",
    "### ### a p+1-by-p+1 matrix with the \"lambda_param\" on the diagonal\n",
    "### ### p+1-by-p+1 because of the prepended \"ones\".\n",
    "\n",
    "### NB: Pay close attention to the expected format of the returned\n",
    "### weights. It is different / simplified from Assignment 1.\n",
    "\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "def ridge_regression_weights(input_x, output_y, lambda_param):\n",
    "    if input_x.shape[0] < input_x.shape[1]:\n",
    "        input_x = input_x.T\n",
    "        \n",
    "    output_y=output_y.T\n",
    "        \n",
    "    ones = np.ones((len(output_y), 1), dtype=int)\n",
    "    \n",
    "    augmented_x = np.concatenate((ones, input_x), axis=1)\n",
    "    \n",
    "    lambda_factor=(np.linalg.inv(np.matmul(np.transpose(augmented_x), augmented_x)+lambda_param))\n",
    "    left_multiplier=np.matmul(lambda_factor,np.transpose(augmented_x))\n",
    "    \n",
    "    weights = np.matmul(left_multiplier, output_y) \n",
    "    \n",
    "    return weights  \n",
    "    \n",
    "    \"\"\"Calculate ridge regression least squares weights.\n",
    "    \n",
    "    Positional arguments:\n",
    "        input_x -- 2-d matrix of input data\n",
    "        output_y -- 1-d numpy array of target values\n",
    "        lambda_param -- lambda parameter that controls how heavily\n",
    "            to penalize large weight values\n",
    "        \n",
    "    Example:\n",
    "        training_y = np.array([208500, 181500, 223500, \n",
    "                                140000, 250000, 143000, \n",
    "                                307000, 200000, 129900, \n",
    "                                118000])\n",
    "                                \n",
    "        training_x = np.array([[1710, 1262, 1786, \n",
    "                                1717, 2198, 1362, \n",
    "                                1694, 2090, 1774, \n",
    "                                1077], \n",
    "                               [2003, 1976, 2001,\n",
    "                               1915, 2000, 1993, \n",
    "                                2004, 1973, 1931, \n",
    "                                1939]])\n",
    "        lambda_param = 10\n",
    "        \n",
    "        rrw = ridge_regression_weights(training_x, training_y, lambda_param)\n",
    "        \n",
    "        print(rrw) #--> np.array([-576.67947107,   77.45913349,   31.50189177])\n",
    "        print(rrw[2]) #--> 31.50189177\n",
    "        \n",
    "    Assumptions:\n",
    "        -- output_y is a vector whose length is the same as the\n",
    "        number of observations in input_x\n",
    "        -- lambda_param has a value greater than 0\n",
    "    \"\"\"\n",
    "    \n",
    "    #weights = np.array([])\n",
    "    #return weights\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-685.97570814   77.45958603   31.55703313]\n"
     ]
    }
   ],
   "source": [
    "output_y = np.array([208500, 181500, 223500, \n",
    "                                140000, 250000, 143000, \n",
    "                                307000, 200000, 129900, \n",
    "                                118000])\n",
    "                                \n",
    "input_x = np.array([[1710, 1262, 1786, \n",
    "                    1717, 2198, 1362, \n",
    "                    1694, 2090, 1774, 1077], \n",
    "                    [2003, 1976, 2001, \n",
    "                    1915, 2000, 1993, \n",
    "                    2004, 1973, 1931, \n",
    "                    1939]])\n",
    "lambda_param = 10\n",
    "rrw = ridge_regression_weights(input_x, output_y, lambda_param)\n",
    "print (rrw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting the  Î»  parameter\n",
    "For our final function before looking at the sklearn implementation of ridge regression, we will create a hyper-parameter tuning algorithm.\n",
    "\n",
    "In ridge regression, we must pick a value for  Î» . We have some intuition about  Î»Î»  from the equations that define it: small values tend to emulate the results from Least Squares, while large values will reduce the dimensionality of the problem. But the choice of  Î»  can be motivated with a more precise quantitative treatment.\n",
    "\n",
    "Eventually, we will look to choose the value of  Î»  that minimizes validation error, which we will determine using  kk -fold cross-validation.\n",
    "\n",
    "For this example here, we will solve a simpler problem: Find a value that minimizes the list returned by the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Example of hiden function below:\n",
    "\n",
    "### `hidden` takes a single number as a parameter (int or float) and returns a list of 1000 numbers\n",
    "### the input must be between 0 and 50 exclusive\n",
    "\n",
    "def hidden(hp):\n",
    "    if (hp<=0) or (hp >= 50):\n",
    "        print(\"input out of bounds\")\n",
    "    \n",
    "    nums = np.logspace(0,5,num = 1000)\n",
    "    vals = nums** 43.123985172351235134687934\n",
    "    \n",
    "    user_vals = nums** hp\n",
    "    \n",
    "    return vals-user_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### Code a function called \"minimize\"\n",
    "### ACCEPT one input: a function.\n",
    "\n",
    "### That function will be similar to `hidden` created above and available for your exploration.\n",
    "### Like 'hidden', the passed function will take a single argument, a number between 0 and 50 exclusive \n",
    "### and then, the function will return a numpy array of 1000 numbers.\n",
    "\n",
    "### RETURN the value that makes the mean of the array returned by 'passed_func' as close to 0 as possible\n",
    "\n",
    "### Note, you will almost certainly NOT be able to find the number that makes the mean exactly 0\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "def minimize( passed_func):\n",
    "    \"\"\"\n",
    "    Find the numeric value that makes the mean of the\n",
    "    output array returned from 'passed_func' as close to 0 as possible.\n",
    "    \n",
    "    Positional Argument:\n",
    "        passed_func -- a function that takes a single number (between 0 and 50 exclusive)\n",
    "            as input, and returns a list of 1000 floats.\n",
    "        \n",
    "    Example:\n",
    "        passed_func = hidden\n",
    "        min_hidden = minimize(passed_func)\n",
    "        print(round(min_hidden,4))\n",
    "        #--> 43.1204 (answers will vary slightly, must be close to 43.123985172351)\n",
    "    \n",
    "    \"\"\"\n",
    "    # Create values to test\n",
    "    test_vals = np.linspace(.1,49,1000)\n",
    "    \n",
    "    # Find mean of returned array from function\n",
    "    ret_vals = [abs(np.mean(passed_func(x))) for x in test_vals]\n",
    "    \n",
    "    # Find smallest mean\n",
    "    min_mean = min(ret_vals)\n",
    "    \n",
    "    # Return the test value that creates the smallest mean\n",
    "    return test_vals[ret_vals.index(min_mean)]\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.126126126126124"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passed_func = hidden\n",
    "min_hidden = minimize(passed_func)\n",
    "min_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2747747747747749"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lambda_search_func(lambda_param):\n",
    "    \n",
    "    # Define X and y\n",
    "    # with preprocessing\n",
    "    df = preprocess_for_regularization(data.head(50),'SalePrice', ['GrLivArea','YearBuilt'])\n",
    "    \n",
    "    y_true = df['SalePrice'].values\n",
    "    X = df[['GrLivArea','YearBuilt']].values\n",
    "    \n",
    "    # Calculate Weights then use for predictions\n",
    "    weights = ridge_regression_weights(X, y_true, lambda_param )\n",
    "    y_pred = weights[0] + np.matmul(X,weights[1:])\n",
    "    \n",
    "    # Calculate Residuals\n",
    "    resid = y_true - y_pred\n",
    "    \n",
    "    # take absolute value to tune on mean-absolute-deviation\n",
    "    # Alternatively, could use:\n",
    "    # return resid **2-S\n",
    "    # for tuning on mean-squared-error\n",
    "    \n",
    "    return abs(resid)\n",
    "\n",
    "minimize(lambda_search_func)    # --> about 2.9414414414414414"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge Regression in sklearn\n",
    "Below gives the syntax for implementing ridge regression in sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeastSquares Intercept: -2024976.362585636 Coefs: [  95.16733349 1045.86241944] \n",
      "\n",
      "Ridge alpha = 43.5 Intercept: -2024906.8759648188 Coefs: [  95.1677299  1045.82686498] \n",
      "\n",
      "Ridge, alpha = 0 Intercept: -2024976.3625856352 Coefs: [  95.16733349 1045.86241944] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "\n",
    "### Note, the \"alpha\" parameter defines regularization strength.\n",
    "### Lambda is a reserved word in `Python` -- Thus \"alpha\" instead\n",
    "\n",
    "### An alpha of 0 is equivalent to least-squares regression\n",
    "lr = LinearRegression()\n",
    "reg = Ridge(alpha = 43.5)\n",
    "reg0 = Ridge(alpha = 0)\n",
    "\n",
    "# Notice how the consistent sklearn syntax may be used to easily fit many kinds of models\n",
    "for m, name in zip([lr, reg, reg0], [\"LeastSquares\",\"Ridge alpha = 43.5\",\"Ridge, alpha = 0\"]):\n",
    "    \n",
    "    m.fit(data[['GrLivArea','YearBuilt']], data['SalePrice'])\n",
    "    print(name, \"Intercept:\", m.intercept_, \"Coefs:\",m.coef_,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
